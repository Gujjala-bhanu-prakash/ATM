# Install necessary libraries
!pip install transformers gradio torch openai-whisper

# Import required libraries

from transformers import pipeline
import gradio as gr
import whisper

# Load Whisper model for speech-to-text
stt_model = whisper.load_model("base")

# Load Hugging Face emotion detection model
emotion_classifier = pipeline("text-classification", model="bhadresh-savani/distilbert-base-uncased-emotion")

# Backend: Function to transcribe speech to text
def transcribe_speech(audio):
    # Transcribe the audio using Whisper
    audio = whisper.load_audio(audio)
    audio = whisper.pad_or_trim(audio)
    mel = whisper.log_mel_spectrogram(audio).to(stt_model.device)
    options = whisper.DecodingOptions(fp16 = False)
    result = whisper.decode(stt_model, mel, options)

    # Return the transcribed text
    return result.text

# Backend: Function to predict emotion from transcribed text
def predict_emotion_from_text(text):
    # Perform emotion classification
    result = emotion_classifier(text)[0]
    emotion = result['label']
    confidence = result['score']

    # Return the emotion and confidence
    return f"Predicted Emotion: {emotion}\nConfidence: {confidence:.2f}"

# Backend: Function that combines transcription and emotion detection
def transcribe_and_detect_emotion(audio):
    # Step 1: Transcribe the speech into text
    text = transcribe_speech(audio)

    # Step 2: Detect emotion from the transcribed text
    return predict_emotion_from_text(text)

# Frontend: Gradio Interface using Microphone input for speech-to-text and emotion detection
interface = gr.Interface(
    fn=transcribe_and_detect_emotion,        # Backend function
    inputs=gr.Audio(type="filepath"),        # Input: Microphone audio (no 'source' argument)
    outputs="text",                          # Output: Predicted emotion and confidence
    title="Speech Emotion Detection",        # Title for the UI
    description="Speak into the microphone, and the system will detect the emotion in your speech." # UI description
)

# Launch the Gradio interface
interface.launch(share=True)
